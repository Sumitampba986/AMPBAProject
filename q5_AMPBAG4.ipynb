{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-17T16:56:09.085673400Z",
     "start_time": "2023-12-17T16:56:07.387252500Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from summa import keywords\n",
    "from summa import summarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-17T16:55:53.363407300Z",
     "start_time": "2023-12-17T16:55:37.559641900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting summa\n",
      "  Using cached summa-1.2.0.tar.gz (54 kB)\n",
      "Requirement already satisfied: scipy>=0.19 in c:\\users\\sumit\\anaconda3\\lib\\site-packages (from summa) (1.7.1)\n",
      "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in c:\\users\\sumit\\anaconda3\\lib\\site-packages (from scipy>=0.19->summa) (1.20.3)\n",
      "Building wheels for collected packages: summa\n",
      "  Building wheel for summa (setup.py): started\n",
      "  Building wheel for summa (setup.py): finished with status 'done'\n",
      "  Created wheel for summa: filename=summa-1.2.0-py3-none-any.whl size=54410 sha256=aa8f97a83f1044436c19ea578ceab9cafd13d622a368aefe701a3ca256578730\n",
      "  Stored in directory: c:\\users\\sumit\\appdata\\local\\pip\\cache\\wheels\\ed\\2c\\5f\\a0ccc5955d44d2cea78729f4425e73f818d2629517f7af0f8b\n",
      "Successfully built summa\n",
      "Installing collected packages: summa\n",
      "Successfully installed summa-1.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install summa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****************************\n",
    "1 Rating \n",
    "****************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-17T16:56:22.370551800Z"
    },
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      overall      reviewerID  \\\n",
      "2           1  A1BJHRQDYVAY2J   \n",
      "18          1  A3VJPFC93LY4OS   \n",
      "19          1  A1N8M648G5E2BM   \n",
      "34          1   AH4NKNB6TYXRE   \n",
      "132         1  A1XW7E1XH2B7KU   \n",
      "...       ...             ...   \n",
      "6074        1   ACIEGJRVPVSWU   \n",
      "6075        1  A1XS2X9J8LH4EX   \n",
      "6076        1  A1J3GMAV27V6TJ   \n",
      "6077        1   A7AT3YVHNBWKD   \n",
      "6078        1   AETE9DPV26QKE   \n",
      "\n",
      "                                             reviewText  \n",
      "2     IF YOU ARE TAKING THIS CLASS DON\"T WASTE YOUR ...  \n",
      "18    Didn't help me much in my course.  I didn't le...  \n",
      "19    Disappointing textbook. To start, the lack of ...  \n",
      "34    Summary: EXTREMELY slow pace, awful stilted na...  \n",
      "132   I hate giving these bad reviews but this softw...  \n",
      "...                                                 ...  \n",
      "6074  I am using Win98SE on a PIII800 with a HP9510 ...  \n",
      "6075  THIS IS THE BIGGIST CON SINCE KING CONG I HAVE...  \n",
      "6076  I purchased this software about two weeks ago....  \n",
      "6077  No Stars, really. The compatibility issue is a...  \n",
      "6078  After several years of satisfactory service fr...  \n",
      "\n",
      "[1000 rows x 3 columns]\n",
      "       overall      reviewerID  \\\n",
      "99           1   AQAK0E9YXVR68   \n",
      "182          1  A33K5AVSUTDEFY   \n",
      "241          1   AUMOYF77KX4UZ   \n",
      "303          1  A17AM57B9UYTPQ   \n",
      "366          1  A2O6SU5YDVSDN4   \n",
      "...        ...             ...   \n",
      "17293        1  A3CS46QPM9RVNS   \n",
      "17313        1  A1YF3OX7ZENRIE   \n",
      "17314        1  A1QOGVFZK2VPBQ   \n",
      "17315        1  A1QOGVFZK2VPBQ   \n",
      "17326        1  A25JRIAUFLORMS   \n",
      "\n",
      "                                              reviewText  \n",
      "99                           Books are very tiny in size  \n",
      "182    Have seen a lot of these patterns before. The ...  \n",
      "241    I have only returned two books in my life, and...  \n",
      "303    I found the book just did not live up to my ex...  \n",
      "366    Have any of the 5 star reviewers actually used...  \n",
      "...                                                  ...  \n",
      "17293  Domestic come close to the Sharpie Oil.  Light...  \n",
      "17313  Totally my own fault as I misread. Thought I w...  \n",
      "17314  Beware that even though the product descriptio...  \n",
      "17315  Beware that even though the product descriptio...  \n",
      "17326  It has a warning label on each one that says i...  \n",
      "\n",
      "[1000 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# READING THE FILE and creating base dataframe for Software and Arts_Crafts_and_Sewing review comments\n",
    "\n",
    "# PART1\n",
    "# Source file path for software reviews \n",
    "json_file_path = r'C:\\Users\\sumit\\Desktop\\ISB\\Classwork\\Text Analytics_R2\\Grp Assign\\Software.json'\n",
    "\n",
    "\n",
    "# Read the JSON file and load into the dataframe\n",
    "df_sowftware = pd.read_json(json_file_path, lines=True)\n",
    "\n",
    "# Creating the base dataframe \n",
    "base_df_software = df_sowftware[df_sowftware['overall']==1]\n",
    "base_df_software = base_df_software.head(1000)\n",
    "# print(base_df_software)\n",
    "pruned_df_software =base_df_software[['overall','reviewerID','reviewText']]\n",
    "pruned_df_software_r1 = pruned_df_software.dropna()\n",
    "print(pruned_df_software_r1)\n",
    "\n",
    "# *****************************************************#\n",
    "# Part2\n",
    "# Source file path for Arts_Crafts_and_Sewing \n",
    "json_file_path = r'C:\\Users\\sumit\\Desktop\\ISB\\Classwork\\Text Analytics_R2\\Grp Assign\\Arts_Crafts_and_Sewing_1.json'\n",
    "\n",
    "# Read the JSON file and load into the dataframe\n",
    "df_Arts_Crafts_and_Sewing = pd.read_json(json_file_path, lines=True)\n",
    "\n",
    "# Creating the base dataframe \n",
    "base_df_Arts_Crafts_and_Sewing = df_Arts_Crafts_and_Sewing[df_Arts_Crafts_and_Sewing['overall']==1]\n",
    "base_df_Arts_Crafts_and_Sewing = base_df_Arts_Crafts_and_Sewing.head(1000)\n",
    "pruned_df_Arts_Crafts_and_Sewing = base_df_Arts_Crafts_and_Sewing[['overall','reviewerID','reviewText']]\n",
    "pruned_df_Arts_Crafts_and_Sewing_r1 = pruned_df_Arts_Crafts_and_Sewing.dropna()\n",
    "print(pruned_df_Arts_Crafts_and_Sewing_r1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "#  Combining the dataset\n",
    "pruned_df_r1 = pd.concat([pruned_df_software_r1, pruned_df_Arts_Crafts_and_Sewing_r1],ignore_index=True)\n",
    "# pruned_df_r1 = pruned_df_r1['reviewText'].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take the first 1000 “rating-1.0” reviews from each category (2000 in total). Summarize them to 1% (in terms of words) using summa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     summary\n",
      "0           \n",
      "1           \n",
      "2           \n",
      "3           \n",
      "4           \n",
      "...      ...\n",
      "1995        \n",
      "1996        \n",
      "1997        \n",
      "1998        \n",
      "1999        \n",
      "\n",
      "[2000 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# Function to apply Summa summarization to a text column\n",
    "def generate_summary(text):\n",
    "    # Using Summa's summarizer function with extractive summarization method\n",
    "    summary = summarizer.summarize(text, ratio=0.01) \n",
    "    return summary\n",
    "\n",
    "\n",
    "\n",
    "# Apply the function to the 'text' column and create a new 'summary' column\n",
    "pruned_df_r1['summary'] = pruned_df_r1['reviewText'].apply(generate_summary)\n",
    "\n",
    "# Display the DataFrame with the summary column\n",
    "print(pruned_df_r1[['summary']])\n",
    "\n",
    "pruned_df_r1.to_csv('summary.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Summarize them to approximately 300 words using summa and send across your summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                summary\n",
      "0     IF YOU ARE TAKING THIS CLASS DON\"T WASTE YOUR ...\n",
      "1     Didn't help me much in my course.\\nI didn't le...\n",
      "2     Disappointing textbook.\\nTo start, the lack of...\n",
      "3     Summary: EXTREMELY slow pace, awful stilted na...\n",
      "4     I hate giving these bad reviews but this softw...\n",
      "...                                                 ...\n",
      "1995  Domestic come close to the Sharpie Oil.\\nLight...\n",
      "1996  Totally my own fault as I misread.\\nThought I ...\n",
      "1997  Beware that even though the product descriptio...\n",
      "1998  Beware that even though the product descriptio...\n",
      "1999  It has a warning label on each one that says i...\n",
      "\n",
      "[2000 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "from summa import summarizer\n",
    "\n",
    "def generate_summary(text, max_words=300):\n",
    "    # Using Summa's summarizer function without ratio\n",
    "    summary = summarizer.summarize(text, words=300)  # Limit summary to the 300 word count\n",
    "    return summary\n",
    "\n",
    "# Apply the function to the 'reviewText' column and create a new 'summary' column\n",
    "pruned_df_r1['summary'] = pruned_df_r1['reviewText'].apply(lambda x: generate_summary(x, max_words=300))\n",
    "\n",
    "# Display the DataFrame with the summary column\n",
    "print(pruned_df_r1[['summary']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*********************\n",
    "5 Rating\n",
    "*********************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      overall      reviewerID  \\\n",
      "4           5  A2JZTTBSLS1QXV   \n",
      "7           5  A35UC8LHA6TILH   \n",
      "8           5  A2IH0AJPR7IWG3   \n",
      "9           5   AL87GELNJGOH3   \n",
      "11          5  A3HB3SSFVVZNH0   \n",
      "...       ...             ...   \n",
      "1595        5  A2P55ALZAM0QIB   \n",
      "1596        5   AQXV4EXL64PH7   \n",
      "1597        5  A3ELRVYSIHE4CK   \n",
      "1598        5   ABOTN916JLKP1   \n",
      "1599        5  A2CP9N58OE9FE0   \n",
      "\n",
      "                                             reviewText  \n",
      "4     I have used LearnSmart and can officially say ...  \n",
      "7     i got this book on amazon and it ended up savi...  \n",
      "8     I was very happy with this purchase because th...  \n",
      "9     Recieved in a timely manner- book in great con...  \n",
      "11    This was the textbook that I used for my E-Com...  \n",
      "...                                                 ...  \n",
      "1595  This product provided all the necessary forms ...  \n",
      "1596  Exactly what I needed- easy to use and looks t...  \n",
      "1597  This software met my expectations and was exac...  \n",
      "1598  The DVD includes installation files for Window...  \n",
      "1599  Excellent! What a fantastic, versatile softwar...  \n",
      "\n",
      "[1000 rows x 3 columns]\n",
      "      overall      reviewerID  \\\n",
      "0           5  A3U4E9PIZ8OWH1   \n",
      "1           5  A3945D2TJ0PI86   \n",
      "2           5  A2WZK72HLQ7SPT   \n",
      "3           5  A1Q7YJ1NPE6E0W   \n",
      "4           5  A2846L8Q507JC4   \n",
      "...       ...             ...   \n",
      "1288        5  A2GPJETQN6OT8C   \n",
      "1289        5  A35W2X8LFT8GVJ   \n",
      "1290        5  A1QQ71SRX4824L   \n",
      "1291        5  A3M4VS2SYANE2L   \n",
      "1292        5   A76EWAMIDN2N5   \n",
      "\n",
      "                                             reviewText  \n",
      "0     I've read this book already and I've got plans...  \n",
      "1                            Nicely written directions.  \n",
      "2                                               love it  \n",
      "3     Good additional knitting reference to have ava...  \n",
      "4     A gazillion pattern stitches, lucidly explaine...  \n",
      "...                                                 ...  \n",
      "1288  Who knew getting lovely file folders was becom...  \n",
      "1289  I am going to use these for my client files.  ...  \n",
      "1290                           Finally, pretty folders!  \n",
      "1291  Love the quality and artwork of Cavalini.  The...  \n",
      "1292  I purchased these to use them as dainty client...  \n",
      "\n",
      "[1000 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# READING THE FILE and creating base dataframe for Software and Arts_Crafts_and_Sewing review comments\n",
    "\n",
    "# PART1\n",
    "# Source file path for software reviews\n",
    "#json_file_path = '/Users/anirudhyadav/Documents/PlayArea/EDA/Software.json'\n",
    "#testing Path\n",
    "json_file_path = r'C:\\Users\\sumit\\Desktop\\ISB\\Classwork\\Text Analytics_R2\\Grp Assign\\Software.json'\n",
    "\n",
    "# Read the JSON file and load into the dataframe\n",
    "df_sowftware = pd.read_json(json_file_path, lines=True)\n",
    "\n",
    "# Creating the base dataframe \n",
    "base_df_software = df_sowftware[df_sowftware['overall']==5]\n",
    "base_df_software = base_df_software.head(1000)\n",
    "# print(base_df_software)\n",
    "pruned_df_software =base_df_software[['overall','reviewerID','reviewText']]\n",
    "pruned_df_software_r5 = pruned_df_software.dropna()\n",
    "print(pruned_df_software_r5)\n",
    "\n",
    "# *****************************************************#\n",
    "# Part2\n",
    "# Source file path for Arts_Crafts_and_Sewing \n",
    "#json_file_path = '/Users/anirudhyadav/Documents/PlayArea/EDA/Arts_Crafts_and_Sewing.json'\n",
    "\n",
    "#Testing Path\n",
    "json_file_path = r'C:\\Users\\sumit\\Desktop\\ISB\\Classwork\\Text Analytics_R2\\Grp Assign\\Arts_Crafts_and_Sewing_1.json'\n",
    "\n",
    "# Read the JSON file and load into the dataframe\n",
    "df_Arts_Crafts_and_Sewing = pd.read_json(json_file_path, lines=True)\n",
    "\n",
    "# Creating the base dataframe \n",
    "base_df_Arts_Crafts_and_Sewing = df_Arts_Crafts_and_Sewing[df_Arts_Crafts_and_Sewing['overall']==5]\n",
    "base_df_Arts_Crafts_and_Sewing = base_df_Arts_Crafts_and_Sewing.head(1000)\n",
    "pruned_df_Arts_Crafts_and_Sewing = base_df_Arts_Crafts_and_Sewing[['overall','reviewerID','reviewText']]\n",
    "pruned_df_Arts_Crafts_and_Sewing_r5 = pruned_df_Arts_Crafts_and_Sewing.dropna()\n",
    "print(pruned_df_Arts_Crafts_and_Sewing_r5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Combining the dataset\n",
    "pruned_df_r5 = pd.concat([pruned_df_software_r5, pruned_df_Arts_Crafts_and_Sewing_r5],ignore_index=True)\n",
    "# pruned_df_r1 = pruned_df_r1['reviewText'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     summary\n",
      "0           \n",
      "1           \n",
      "2           \n",
      "3           \n",
      "4           \n",
      "...      ...\n",
      "1995        \n",
      "1996        \n",
      "1997        \n",
      "1998        \n",
      "1999        \n",
      "\n",
      "[2000 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# Function to apply Summa summarization to a text column\n",
    "def generate_summary(text):\n",
    "    # Using Summa's summarizer function with extractive summarization method\n",
    "    summary = summarizer.summarize(text, ratio=0.01) \n",
    "    return summary\n",
    "\n",
    "\n",
    "\n",
    "# Apply the function to the 'text' column and create a new 'summary' column\n",
    "pruned_df_r5['summary'] = pruned_df_r5['reviewText'].apply(generate_summary)\n",
    "\n",
    "# Display the DataFrame with the summary column\n",
    "print(pruned_df_r5[['summary']])\n",
    "\n",
    "pruned_df_r5.to_csv('summary.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Summarize approximately 300 words using summa and send across your summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                summary\n",
      "0     I have used LearnSmart and can officially say ...\n",
      "1     i got this book on amazon and it ended up savi...\n",
      "2     I was very happy with this purchase because th...\n",
      "3     Recieved in a timely manner- book in great con...\n",
      "4     This was the textbook that I used for my E-Com...\n",
      "...                                                 ...\n",
      "1995  Who knew getting lovely file folders was becom...\n",
      "1996  I am going to use these for my client files.\\n...\n",
      "1997                                                   \n",
      "1998  Love the quality and artwork of Cavalini.\\nThe...\n",
      "1999  I purchased these to use them as dainty client...\n",
      "\n",
      "[2000 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "from summa import summarizer\n",
    "\n",
    "def generate_summary(text, max_words=300):\n",
    "    # Using Summa's summarizer function without ratio\n",
    "    summary = summarizer.summarize(text, words=max_words)  # Limit summary to the specified word count\n",
    "    return summary\n",
    "\n",
    "# Apply the function to the 'reviewText' column and create a new 'summary' column\n",
    "pruned_df_r5['summary'] = pruned_df_r5['reviewText'].apply(lambda x: generate_summary(x, max_words=300))\n",
    "\n",
    "# Display the DataFrame with the summary column\n",
    "print(pruned_df_r5[['summary']])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
